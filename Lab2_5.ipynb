{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPfoPSOlzvmn"
   },
   "source": [
    "## Lab 2: final challenges\n",
    "\n",
    "__Вам предлагается решить задачу классификации сигналов или задачу классификации изображений. Или обе ;)__\n",
    "\n",
    "__Выполнение этих заданий не является обязательным, но позитивно повлияет на вашу итоговую оценку. Успехов!__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_RLzfJKzvnV"
   },
   "source": [
    "### Part 5. Dogs classification (2+ points)\n",
    "__Disclaimer__: Это опциональная часть задания. Здесь придется экспериментировать, подбирать оптимальную структуру сети для решения задачи и активно искать подскзаки в сети.\n",
    "\n",
    "Предлагаем вам решить задачу классификации пород собак. Вы можете обучить сеть с нуля или же воспользоваться методом fine-tuning'а. Полезная ссылка на [предобученные модели](https://pytorch.org/docs/stable/torchvision/models.html).\n",
    "\n",
    "Данные можно скачать [отсюда](https://www.dropbox.com/s/vgqpz2f1lolxmlv/data.zip?dl=0). Датасет представлен 50 классами пород собак, которые можно найти в папке train в соответствующих директориях. При сдаче данной части задания вместе с ноутбуком необходимо отправить .csv-файл с предсказаниями классов тестовой выборки в формате: <имя изображения>,<метка класса> по одному объекту на строку. Ниже приведите код ваших экспериментов и короткий вывод по их результатам.\n",
    "\n",
    "Будут оцениваться качество классификации (accuracy) на тестовой выборке (2 балла) и проведенные эксперименты (1 балл).\n",
    "Разбалловка следующая:\n",
    "* $>=$93% - 2 points\n",
    "* $>=$84% - 1.5 points\n",
    "* $>=$70% - 0.75 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет\n",
    "\n",
    "Я взял предобученную на Imagenet ResNet-152, обучил ее методом fine-tuning, добавив линейный слой в конце. Также попробовал добавлять скедулеры и количество эпох, чтобы улучшать перфоманс модели. В результате получилась accuracy = 0.8838. После этого  я добавил аугментации (флипы, повороты) и благодаря этому точность выросла до 0.9181 на валидационных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueCR9la6FKge",
    "outputId": "08212027-28d4-4c86-9604-704233664e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cq6cjp3ozvnW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, models, datasets\n",
    "import torch\n",
    "\n",
    "image_std = [0.229, 0.224, 0.225]\n",
    "image_mean = [0.485, 0.456, 0.406]\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees = 20), transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "     transforms.Normalize(image_mean, image_std), transforms.RandomHorizontalFlip()])\n",
    "data_dir = '/content/drive/My Drive/data'\n",
    "datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                                          data_transforms)\n",
    "split1 = int(len(datasets)*0.8)\n",
    "split2 = len(datasets) - split1\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(datasets, [split1, split2])\n",
    "image_datasets = {'train':train_dataset, 'test':val_dataset}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Oibjq0LN3ipP"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = '/content/drive/My Drive/data/test/'\n",
    "test_dataset = []\n",
    "test_nums = []\n",
    "for i in range(1503):\n",
    "  img = Image.open(str(img_path)+str(i)+\".jpeg\")\n",
    "  img = data_transforms(img)\n",
    "  test_dataset.append(img)\n",
    "  test_nums.append(str(i)+\".jpeg\")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "dd8fc8c190284e98ac10d9c7af5f4d38",
      "da68ee2641e541a6865147c92e0d7c62",
      "c5e9a0c89563480690cd48c6af46736d",
      "7fdc1d89b992468592a19e87a30fb3a9",
      "1ca36895f90f418592a7c00dfcdb1f30",
      "544cfea16c7045f9a4cbea71051bdf95",
      "ad48549171f349d2810d333c2e018dc1",
      "67b81aa4b25147f8b432b0ecc2ad3e22",
      "67ac9fa094e74d478005910654102720",
      "291b0a4e049c40cfbc7753441d4ac310",
      "79a91a8559444af6a92b6bf8467f6453"
     ]
    },
    "id": "Dgd0mH8o_7Rm",
    "outputId": "6ff5dd72-d9b6-4b23-bdb9-8400537c638e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8fc8c190284e98ac10d9c7af5f4d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "device = \"cuda\"\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 50)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mQMXqSfBxiHn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "\n",
    "    \n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHiqDJ6KoaEF",
    "outputId": "71ec8f47-8ccd-437a-b657-208d148d7da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.9290 Acc: 0.5393\n",
      "test Loss: 0.4729 Acc: 0.8729\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.9023 Acc: 0.7761\n",
      "test Loss: 0.3113 Acc: 0.9062\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.7393 Acc: 0.7985\n",
      "test Loss: 0.3359 Acc: 0.9097\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.8105\n",
      "test Loss: 0.3468 Acc: 0.8958\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8098\n",
      "test Loss: 0.3248 Acc: 0.9056\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.8195\n",
      "test Loss: 0.3474 Acc: 0.9042\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6103 Acc: 0.8256\n",
      "test Loss: 0.3073 Acc: 0.9104\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.5031 Acc: 0.8582\n",
      "test Loss: 0.3192 Acc: 0.9125\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.5089 Acc: 0.8506\n",
      "test Loss: 0.2994 Acc: 0.9139\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.4772 Acc: 0.8641\n",
      "test Loss: 0.2966 Acc: 0.9153\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.5074 Acc: 0.8501\n",
      "test Loss: 0.2780 Acc: 0.9181\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.5006 Acc: 0.8528\n",
      "test Loss: 0.3205 Acc: 0.9056\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.4991 Acc: 0.8598\n",
      "test Loss: 0.2997 Acc: 0.9104\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.4839 Acc: 0.8678\n",
      "test Loss: 0.2971 Acc: 0.9125\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.5002 Acc: 0.8638\n",
      "test Loss: 0.3089 Acc: 0.9125\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c6y11Le0Sn1U"
   },
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "model_ft.eval()\n",
    "for X_batch in test_loader:\n",
    "  X_batch = X_batch.to(device)\n",
    "  outputs = model_ft(X_batch)\n",
    "  _, preds = torch.max(outputs, 1)\n",
    "  preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H4qXXwOaT4B7"
   },
   "outputs": [],
   "source": [
    "preds_all = torch.cat(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P9sXynyPUiEW"
   },
   "outputs": [],
   "source": [
    "idx_to_class = dict(list(\n",
    "    zip(datasets.class_to_idx.values(), \n",
    "        map(int, datasets.class_to_idx.keys()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Cytry5PmWftN"
   },
   "outputs": [],
   "source": [
    "with open(\"answer_corr.csv\", \"w\") as f:\n",
    "  for i, sample in enumerate(preds_all):\n",
    "    f.write(\"{}.jpeg\".format(str(i)) +\": \" +\n",
    "            str(idx_to_class[int(sample)]) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"Lab2_DL_parts_4_and_5_optional.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ca36895f90f418592a7c00dfcdb1f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79a91a8559444af6a92b6bf8467f6453",
      "placeholder": "​",
      "style": "IPY_MODEL_291b0a4e049c40cfbc7753441d4ac310",
      "value": " 230M/230M [00:02&lt;00:00, 77.5MB/s]"
     }
    },
    "291b0a4e049c40cfbc7753441d4ac310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "544cfea16c7045f9a4cbea71051bdf95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67ac9fa094e74d478005910654102720": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b81aa4b25147f8b432b0ecc2ad3e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79a91a8559444af6a92b6bf8467f6453": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fdc1d89b992468592a19e87a30fb3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ac9fa094e74d478005910654102720",
      "max": 241627721,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67b81aa4b25147f8b432b0ecc2ad3e22",
      "value": 241627721
     }
    },
    "ad48549171f349d2810d333c2e018dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5e9a0c89563480690cd48c6af46736d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad48549171f349d2810d333c2e018dc1",
      "placeholder": "​",
      "style": "IPY_MODEL_544cfea16c7045f9a4cbea71051bdf95",
      "value": "100%"
     }
    },
    "da68ee2641e541a6865147c92e0d7c62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd8fc8c190284e98ac10d9c7af5f4d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5e9a0c89563480690cd48c6af46736d",
       "IPY_MODEL_7fdc1d89b992468592a19e87a30fb3a9",
       "IPY_MODEL_1ca36895f90f418592a7c00dfcdb1f30"
      ],
      "layout": "IPY_MODEL_da68ee2641e541a6865147c92e0d7c62"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}